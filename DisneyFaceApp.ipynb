{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DisneyFaceApp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO63dL0nlad6dJBepWNrE7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takashinnosuke/study_Keras/blob/main/DisneyFaceApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDRxIdIk946_",
        "outputId": "c4032480-3629-479a-984d-a09436c20d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 2.32 MiB | 4.03 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/justinpinkney/stylegan2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "# フォルダーの作成\n",
        "!mkdir aligned\n",
        "!mkdir generated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z00Ff-uD-Xxt",
        "outputId": "939d5c8f-5b82-4201-d4e8-6f2396bf6d2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2/stylegan2/stylegan2\n",
            "CPU says hello.\n",
            "cudaErrorNoKernelImageForDevice: no kernel image is available for execution on the device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ffhqモデル(Baseモデル)とblendedモデルのダウンロード\n",
        "import pretrained_networks\n",
        "\n",
        "# use my copy of the blended model to save Doron's download bandwidth\n",
        "# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n",
        "#blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\"\n",
        "blended_url = \"https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59\" \n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
        "_, _, Gs = pretrained_networks.load_networks(ffhq_url)"
      ],
      "metadata": {
        "id": "iqNFaqoi-QHJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像表示\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = glob.glob(folder)\n",
        "    files.sort()\n",
        "    images=[]\n",
        "    for i in range(len(files)):\n",
        "        img = Image.open(files[i])    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示\n",
        "import PIL.Image\n",
        "def display(latents):\n",
        "    \n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  \n",
        "    fig = plt.figure(figsize=(30, 40))   \n",
        "    for i in range(len(latents)):\n",
        "        vec = latents[i].reshape(1,18,512)\n",
        "        images =  Gs_blended.components.synthesis.run(vec, randomize_noise=False, **synthesis_kwargs)  \n",
        "        images = images.transpose((0,2,3,1))     \n",
        "        PIL.Image.fromarray(images[0], 'RGB')   \n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images[0])\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# 潜在変数(latents)の順番を指定して、トランジションのGIFを作成する\n",
        "import os\n",
        "\n",
        "def generate_gif(latents, idx):\n",
        "\n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "\n",
        "    image_gif = []\n",
        "    os.makedirs('my/gif', exist_ok=True)\n",
        "    for j in range(len(idx)-1):\n",
        "        for i in range(20):\n",
        "            latent = latents[idx[j]]+(latents[idx[j+1]]-latents[idx[j]])*i/19\n",
        "            latent = latent.reshape(1, 18, 512)\n",
        "            images =  Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs) \n",
        "            images = images.transpose((0,2,3,1)) \n",
        "            image_one = PIL.Image.fromarray(images[0], 'RGB')\n",
        "            image_gif.append(image_one.resize((256,256))) \n",
        "\n",
        "    image_gif[0].save('./my/gif/anime.gif', save_all=True, append_images=image_gif[1:],\n",
        "                      duration=100, loop=0) "
      ],
      "metadata": {
        "id": "Ooz4kjRi-udC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 顔画像の切り取り\n",
        "!python align_images.py raw aligned\n",
        "display_pic('./aligned/*.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "bmWPKR8Q-5Ri",
        "outputId": "7ba98df0-bd36-462d-ca07-7eac9fea7edf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"align_images.py\", line 33, in <module>\n",
            "    for img_name in [x for x in os.listdir(RAW_IMAGES_DIR) if x[0] not in '._']:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'raw'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 顔画像の潜在変数を求める \n",
        "!python project_images.py --num-steps 500 aligned generated\n",
        "display_pic('./generated/*.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "F7cPeBa4-8Pt",
        "outputId": "51002373-b7ba-49c6-963a-7871156a6b2b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"...\n",
            "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl ... done\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Downloading http://d36zk2xti64re0.cloudfront.net/stylegan1/networks/metrics/vgg16_zhang_perceptual.pkl ... done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 潜在変数wからアニメ画像を生成する\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "from pathlib import Path\n",
        "\n",
        "latent_dir = Path(\"generated\")\n",
        "latents = sorted(latent_dir.glob(\"*.npy\"))\n",
        "\n",
        "for i, latent_file in enumerate(latents):\n",
        "  latent = np.load(latent_file)\n",
        "  latent = np.expand_dims(latent,axis=0)\n",
        "  synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
        "  Image.fromarray(images.transpose((0,2,3,1))[0], 'RGB').save(latent_file.parent / (f\"{latent_file.stem}-toon.jpg\"))\n",
        "  \n",
        "  if i == 0:\n",
        "    latents = latent\n",
        "  else:\n",
        "    latents = np.concatenate([latents, latent])  \n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示する\n",
        "display(latents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Rm-rBOU0--P4",
        "outputId": "c13f39b9-86f7-44e2-8cf4-02fef2113eb7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 潜在変数(latents)の順番を指定して、トランジションGIFを作成する\n",
        "from IPython.display import Image\n",
        "generate_gif(latents,[0,1,2,0])\n",
        "Image('./my/gif/anime.gif', format='png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "lzBLz9Z-_Aru",
        "outputId": "91c7050b-2743-4002-c155-478a759b50f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-59593ac63fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 潜在変数(latents)の順番を指定して、トランジションGIFを作成する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerate_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./my/gif/anime.gif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-79c320aceac5>\u001b[0m in \u001b[0;36mgenerate_gif\u001b[0;34m(latents, idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mGs_blended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msynthesis_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}